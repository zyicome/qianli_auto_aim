# 期望与鼓舞
```
2024.8.22->2024.9.12 第一版
作出一套属于QianLi的自瞄程序，属于yyb的自瞄
终点很远，但是每前进的一小步都会离终点更进一步
上山的人很多，但山顶的人很少
7分钟的飞驰，源于7000次的测试
```

## 开发流程
```
（1）分析基本功能需求和扩展功能需要，先标定出大致方案（找优解），在程序中先打上注释，保留扩展功能的接口
（2）按顺序补全功能，并在编写程序的过程中思考可扩展，可提升项，并尽量保证代码的美观和整洁，保留充足的接口
（3）部分代码完整后进行测试，确保功能的可实施性和能力
（4）完整性测试及优化
```

### 整体功能前瞻
```
（1）程序稳定运行，无bug，不会异常崩溃
（2）能力突出，比现有程序展现更高的能力和潜力
（3）有充足可视化功能，确保纠错方便，调参方便，使用方便，上手方便
（4）代码的美观性和整洁性，封装完整，具有规范性和可扩展性

不要着急！！！！！！！！尽力即可
```

# 方案
```
                               -> 装甲板识别（神经网络 && 神经网络+传统视觉）-> 分类处理（切换装甲板 && 可忽略项 && 优先项）做全管理模块 ->（从camera_optical_frame坐标系变换为odom坐标系）预测追踪（单跟踪节约性能 && 提高预测精确度 && 预测时间考虑）->（从odom坐标系到shoot坐标系）弹道解算（整体时间分析 && 模型精准度考虑）-> 自动校准？（识别小弹丸？图片校准？）
工业相机图片读取（海康 && 迈德威视）(留出按键控制不同的方案)
                               -> 能量机关的识别与处理
                               -> 反导实现？
```

# 具体自瞄方案
```
图片读取：节点组件提高通信速率，提高帧率，实时帧率显示
        输出：Image
        可视化：图片(->帧率显示?)

神经网络：缩小图片大小（300-300大小图片）（区域性检测？），加快运行速度（核显采用openvino加速，独显采用inference_cuda加速即nvinfer），提高帧率，如何计算距离？四点法？需求精准的四个点！
神经网路+传统视觉：灯条识别+数字识别：之前的问题--以等条四个角为四个顶点进行pnp解算，出现如果灯条跳动导致pnp结果大幅跳动的问题！如何提高稳定性？
        输入：Image
        输出：所有探测到装甲板类别、box
        可视化：结果图片显示：包含框中的机器人类别、方框，以及当前锁定的装甲板，帧率，处理时间

分类处理：留出按键切换目标，丢弃当前目标（时间控制？），对一些装甲板类别的忽略，优先处理一些装甲板（比较级）

预测追踪：难点！！！，扩展卡尔曼滤波？优化方式？如何考虑自身的移动(可忽略？)？平移难以命中的问题

弹道解算：整体时间分析！！！从读取到图片确定敌人此刻的位置->程序运行时间->从串口发送到下位机的时间->下位机控制云台摆到对应位置的时间（难以把控！！！？）->拨弹发弹时间->弹丸空中的飞行时间
                 ->关键关注一下节点之间的一个时间戳是否是相同的

自动校准：难点！！！

坐标变换关系：camera_optical_frame->camera_link->gimbal_joint->odom->shoot
```

# 实际自瞄方案
```
图片读取：节点组件提高通信速率，提高帧率，实时帧率显示
        输出：Image，帧率
        可视化：图片

神经网络：640x640 采用openvino加速 四点法框出灯条

预测追踪：双模型预测法
```

# To do 

- [*] 解决pnp对yaw方向姿态解算不准确的问题--投影变换法
- [] 弹道效正和弹道估计
- [] 优化运动方程和精细火控
- [] 实现收敛快速的平移运动模型
- [] 参数更新

# 使用方法
## 环境要求
```
ros2 C++/C
openCV 4.5.4
Cmake
OpenVINO
```

## 编译运行
```
colcon build
. install/setup.bash
ros2 launch rm_startup rm_launch.py
```